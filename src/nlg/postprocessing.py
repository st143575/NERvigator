import json
import argparse
import pandas as pd
from pathlib import Path
from collections import Counter
from typing import Optional, Union, List, Dict


def parse_arguments():
    """Parse command line arguments."""
    parser = argparse.ArgumentParser(description='Natural language generation for NER (0-shot).')
    parser.add_argument('-i', '--input_dir', type=str, default="/mount/studenten-temp1/users/cs/SS2024/cl-team-lab-ner/src/advanced_approach/nlg/output")
    parser.add_argument('-dsn', '--dataset_name', type=str, required=True, help="Name of the dataset, should be one of 'ner-disease', 'ner-gene', 'ner-pol'.")
    parser.add_argument('-o', '--output_dir', type=str, default="/mount/studenten-temp1/users/cs/SS2024/cl-team-lab-ner/src/advanced_approach/nlg/output")
    parser.add_argument('-c', '--cache_dir', type=str, default="/mount/studenten-temp1/users/cs/SS2024/cl-team-lab-ner/cache")
    parser.add_argument('-m', '--model', type=str, default="gpt-4o")
    return parser.parse_args()


def generate_bio_tags(tokens: List[str], model_output: Optional[Union[List, Dict[str, List]]], dataset_name: str, candidate_labels: dict) -> List[str]:
    """
    Map the entity names generated by the model to the BIO tags.
    
    Args:
        tokens: List[str]       List of tokens in the sentence.
        model_output: Optional[Union[List, Dict[str, List]]]     List of entitiy names generated by the model.
        dataset_name: str       Name of the dataset, can be 'ner-disease', 'ner-gene', or 'ner-pol'.

    Returns:
        bio_tags: List[str]     List of BIO tags for each token in the sentence.
    """

    idx2tag = candidate_labels[dataset_name]

    bio_tags = ['O'] * len(tokens)

    # Check dataset name.
    if dataset_name == 'ner-disease' or dataset_name == 'ner-gene':
        assert isinstance(model_output, list)
        
        entity_freq = dict(Counter(model_output))
        for entity, freq in entity_freq.items():
            token_str = " ".join(tokens)
            
            for _ in range(freq):
                start_idx = token_str.find(entity)
                if start_idx == -1:
                    continue
                prefix = token_str[:start_idx]
                start_token_idx = prefix.count(" ")
                end_token_idx = start_token_idx + entity.count(" ")

                if start_token_idx <= end_token_idx and start_token_idx < len(bio_tags):
                    bio_tags[start_token_idx] = idx2tag['1']
                    for i in range(start_token_idx + 1, end_token_idx + 1):
                        if i < len(bio_tags):
                            bio_tags[i] = idx2tag['2']

                token_str = " " + token_str[start_idx+len(entity):]
    
    elif dataset_name == 'ner-pol':
        assert isinstance(model_output, dict)
        
        # Lowercase all entity names in the model output.
        model_output = {polm: [ent.lower() for ent in entities] for polm, entities in model_output.items()}

        for j, (polm, entities) in enumerate(model_output.items()):
            entity_freq = dict(Counter(entities))
            if entity_freq == {}:
                continue
            for entity, freq in entity_freq.items():
                token_str = " ".join(tokens).lower()    # Lowercase the sentence.
                
                for _ in range(freq):
                    start_idx = token_str.find(entity)
                    if start_idx == -1:
                        continue
                    prefix = token_str[:start_idx]
                    start_token_idx = prefix.count(" ")
                    end_token_idx = start_token_idx + entity.count(" ")

                    if start_token_idx <= end_token_idx and start_token_idx < len(bio_tags):
                        bio_tags[start_token_idx] = idx2tag[str(j*2+1)]
                        for i in range(start_token_idx+1, end_token_idx+1):
                            if i < len(bio_tags):
                                bio_tags[i] = idx2tag[str(j*2+2)]

                    token_str = " " + token_str[start_idx+len(entity):]
                    
    else:
        raise ValueError("Invalid dataset name!")

    return bio_tags


def main():
    args = parse_arguments()
    input_dir = Path(args.input_dir)
    output_dir = Path(args.output_dir)
    cache_dir = Path(args.cache_dir)

    # Load model outputs.
    ner_pred_df = pd.read_json(f"{input_dir}/{args.dataset_name}-{args.model}-0-shot.jsonl", lines=True)

    # Assign BIO label to the model output.
    # Load idx2tag.json
    candidate_labels = json.load(open(f"{cache_dir}/idx2tag.json", "r"))

    # Generate BIO tags.
    ner_pred_labels_df = ner_pred_df.copy()
    ner_pred_labels_df['tags_pred'] = [generate_bio_tags(tokens, entities, dataset_name=args.dataset_name, candidate_labels=candidate_labels) for tokens, entities in zip(ner_pred_df['sentence'], ner_pred_df['model_output'])]

    # Write ner_pred_labels_df to file
    ner_pred_labels_df.to_json(f"{output_dir}/{args.dataset_name}-{args.model}-0-shot-labels.jsonl", orient="records", lines=True)


if __name__ == "__main__":
    main()